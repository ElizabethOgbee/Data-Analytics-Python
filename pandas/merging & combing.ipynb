{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0d553e",
   "metadata": {},
   "source": [
    "MERGING AND JOINING.\n",
    "This is used in combining rows from two dataframe based on a common column/key (like id, user_id, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb86efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product_Identifier Supermarket_Identifier Product_Supermarket_Identifier  \\\n",
      "0              DRA12            CHUKWUDI010              DRA12_CHUKWUDI010   \n",
      "1              DRA12            CHUKWUDI013              DRA12_CHUKWUDI013   \n",
      "2              DRA12            CHUKWUDI017              DRA12_CHUKWUDI017   \n",
      "3              DRA12            CHUKWUDI018              DRA12_CHUKWUDI018   \n",
      "4              DRA12            CHUKWUDI035              DRA12_CHUKWUDI035   \n",
      "\n",
      "   Product_Weight Product_Fat_Content  Product_Shelf_Visibility Product_Type  \\\n",
      "0            11.6             Low Fat                  0.068535  Soft Drinks   \n",
      "1            11.6             Low Fat                  0.040912  Soft Drinks   \n",
      "2            11.6             Low Fat                  0.041178  Soft Drinks   \n",
      "3            11.6             Low Fat                  0.041113  Soft Drinks   \n",
      "4            11.6       Ultra Low fat                  0.000000  Soft Drinks   \n",
      "\n",
      "   Product_Price  Supermarket_Opening_Year Supermarket_Size  \\\n",
      "0         357.54                      2005              NaN   \n",
      "1         355.79                      1994             High   \n",
      "2         350.79                      2014              NaN   \n",
      "3         355.04                      2016           Medium   \n",
      "4         354.79                      2011            Small   \n",
      "\n",
      "  Supermarket_Location_Type   Supermarket_Type  Product_Supermarket_Sales  \n",
      "0                 Cluster 3      Grocery Store                     709.08  \n",
      "1                 Cluster 3  Supermarket Type1                    6381.69  \n",
      "2                 Cluster 2  Supermarket Type1                    6381.69  \n",
      "3                 Cluster 3  Supermarket Type2                    2127.23  \n",
      "4                 Cluster 2  Supermarket Type1                    2481.77  \n",
      "  Product_Identifier Supermarket_Identifier Product_Supermarket_Identifier  \\\n",
      "0              DRA12            CHUKWUDI010              DRA12_CHUKWUDI010   \n",
      "1              DRA12            CHUKWUDI013              DRA12_CHUKWUDI013   \n",
      "2              DRA12            CHUKWUDI017              DRA12_CHUKWUDI017   \n",
      "3              DRA12            CHUKWUDI018              DRA12_CHUKWUDI018   \n",
      "4              DRA12            CHUKWUDI035              DRA12_CHUKWUDI035   \n",
      "\n",
      "   Product_Weight Product_Fat_Content  Product_Shelf_Visibility Product_Type  \\\n",
      "0            11.6             Low Fat                  0.068535  Soft Drinks   \n",
      "1            11.6             Low Fat                  0.040912  Soft Drinks   \n",
      "2            11.6             Low Fat                  0.041178  Soft Drinks   \n",
      "3            11.6             Low Fat                  0.041113  Soft Drinks   \n",
      "4            11.6       Ultra Low fat                  0.000000  Soft Drinks   \n",
      "\n",
      "   Product_Price  Supermarket_Opening_Year Supermarket_Size  \\\n",
      "0         357.54                      2005              NaN   \n",
      "1         355.79                      1994             High   \n",
      "2         350.79                      2014              NaN   \n",
      "3         355.04                      2016           Medium   \n",
      "4         354.79                      2011            Small   \n",
      "\n",
      "  Supermarket_Location_Type   Supermarket_Type  Product_Supermarket_Sales  \n",
      "0                 Cluster 3      Grocery Store                     709.08  \n",
      "1                 Cluster 3  Supermarket Type1                    6381.69  \n",
      "2                 Cluster 2  Supermarket Type1                    6381.69  \n",
      "3                 Cluster 3  Supermarket Type2                    2127.23  \n",
      "4                 Cluster 2  Supermarket Type1                    2481.77  \n"
     ]
    }
   ],
   "source": [
    "# 1. pd.merge();: like SQL JOINS (on keys)\n",
    "#  commonly used in column/key (like id, user_id, etc)#\n",
    "import pandas as pd\n",
    "\n",
    "#LOAD BOTH CVS\n",
    "supmkt_df = pd.read_csv('supmkt.csv')\n",
    "supmket_df = pd.read_csv('supmket.csv')\n",
    "\n",
    "print(supmket_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a897883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product_Identifier_x Supermarket_Identifier_x  \\\n",
      "0                DRA12              CHUKWUDI010   \n",
      "1                DRA12              CHUKWUDI010   \n",
      "2                DRA12              CHUKWUDI010   \n",
      "3                DRA12              CHUKWUDI010   \n",
      "4                DRA12              CHUKWUDI010   \n",
      "\n",
      "  Product_Supermarket_Identifier_x  Product_Weight Product_Fat_Content_x  \\\n",
      "0                DRA12_CHUKWUDI010            11.6               Low Fat   \n",
      "1                DRA12_CHUKWUDI010            11.6               Low Fat   \n",
      "2                DRA12_CHUKWUDI010            11.6               Low Fat   \n",
      "3                DRA12_CHUKWUDI010            11.6               Low Fat   \n",
      "4                DRA12_CHUKWUDI010            11.6               Low Fat   \n",
      "\n",
      "   Product_Shelf_Visibility_x Product_Type_x  Product_Price_x  \\\n",
      "0                    0.068535    Soft Drinks           357.54   \n",
      "1                    0.068535    Soft Drinks           357.54   \n",
      "2                    0.068535    Soft Drinks           357.54   \n",
      "3                    0.068535    Soft Drinks           357.54   \n",
      "4                    0.068535    Soft Drinks           357.54   \n",
      "\n",
      "   Supermarket_Opening_Year_x Supermarket_Size_x  ...  \\\n",
      "0                        2005                NaN  ...   \n",
      "1                        2005                NaN  ...   \n",
      "2                        2005                NaN  ...   \n",
      "3                        2005                NaN  ...   \n",
      "4                        2005                NaN  ...   \n",
      "\n",
      "  Product_Supermarket_Identifier_y Product_Fat_Content_y  \\\n",
      "0                DRA12_CHUKWUDI010               Low Fat   \n",
      "1                DRA12_CHUKWUDI013               Low Fat   \n",
      "2                DRA12_CHUKWUDI017               Low Fat   \n",
      "3                DRA12_CHUKWUDI018               Low Fat   \n",
      "4                DRA12_CHUKWUDI035         Ultra Low fat   \n",
      "\n",
      "   Product_Shelf_Visibility_y Product_Type_y Product_Price_y  \\\n",
      "0                    0.068535    Soft Drinks          357.54   \n",
      "1                    0.040912    Soft Drinks          355.79   \n",
      "2                    0.041178    Soft Drinks          350.79   \n",
      "3                    0.041113    Soft Drinks          355.04   \n",
      "4                    0.000000    Soft Drinks          354.79   \n",
      "\n",
      "  Supermarket_Opening_Year_y Supermarket_Size_y  Supermarket_Location_Type_y  \\\n",
      "0                       2005                NaN                    Cluster 3   \n",
      "1                       1994               High                    Cluster 3   \n",
      "2                       2014                NaN                    Cluster 2   \n",
      "3                       2016             Medium                    Cluster 3   \n",
      "4                       2011              Small                    Cluster 2   \n",
      "\n",
      "  Supermarket_Type_y  Product_Supermarket_Sales_y  \n",
      "0      Grocery Store                       709.08  \n",
      "1  Supermarket Type1                      6381.69  \n",
      "2  Supermarket Type1                      6381.69  \n",
      "3  Supermarket Type2                      2127.23  \n",
      "4  Supermarket Type1                      2481.77  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. pd.merge();: like SQL JOINS (on keys)\n",
    "#  commonly used in column/key (like id, user_id, etc)#\n",
    "merged_df = pd.merge(supmkt_df, supmket_df, on='Product_Weight', how='left')\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a9a7a",
   "metadata": {},
   "source": [
    "üîç Result (how='inner'):\n",
    "Only keeps rows with matching Customer_ID in both DataFrames.\n",
    "| Customer\\_ID | Name  | Order\\_Amount |\n",
    "| ------------ | ----- | ------------- |\n",
    "| 1            | Alice | 100           |\n",
    "| 2            | Bob   | 200           |\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Two sample tables\n",
    "customers = pd.DataFrame({\n",
    "    'Customer_ID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'Customer_ID': [1, 2, 4],\n",
    "    'Order_Amount': [100, 200, 150]\n",
    "})\n",
    "\n",
    "# Merge on Customer_ID\n",
    "merged_df = pd.merge(customers, orders, on='Customer_ID', how='inner')\n",
    " merged_df = pd.merge(customers, orders, on='Customer_ID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701a183",
   "metadata": {},
   "source": [
    "| Merge Type | What it does                                |\n",
    "| ---------- | ------------------------------------------- |\n",
    "| `'inner'`  | Only matching rows (default) ‚úÖ            |\n",
    "| `'left'`   | All rows from left file, match if possible  |\n",
    "| `'right'`  | All rows from right file, match if possible |\n",
    "| `'outer'`  | All rows from both, fill missing with `NaN` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b05a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e080fd0",
   "metadata": {},
   "source": [
    "pd.concat()-- STACK ROWS OR COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0fac68",
   "metadata": {},
   "source": [
    "#STACKING ROWS(VERTICAL)\n",
    "# Imagine you split and want to recombine male and female sales#\n",
    "| Gender | Product\\_line | Total |\n",
    "| ------ | ------------- | ----- |\n",
    "| Male   | Food          | 100   |\n",
    "| Female | Clothes       | 200   |\n",
    "| Male   | Electronics   | 150   |\n",
    "| Female | Food          | 250   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c3984a",
   "metadata": {},
   "source": [
    "üß± 2. pd.concat(): Stack Vertically or Horizontally\n",
    "Used when you want to append or combine datasets either:\n",
    "\n",
    "vertically (one below another ‚Äî axis=0)\n",
    "\n",
    "horizontally (side by side ‚Äî axis=1)\n",
    "\n",
    "‚úÖ Example (Vertical):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Name': ['Alice', 'Bob']})\n",
    "df2 = pd.DataFrame({'Name': ['Charlie', 'David']})\n",
    "\n",
    "combined = pd.concat([df1, df2, axis=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789be4f5",
   "metadata": {},
   "source": [
    "| Name    |\n",
    "| ------- |\n",
    "| Alice   |\n",
    "| Bob     |\n",
    "| Charlie |\n",
    "| David   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb8ccd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine you split and want to recombine male & female sales\n",
    "male_df = supmkt_df[supmkt_df['Gender'] == 'Male']\n",
    "female_df = supmkt_df[supmkt_df['Gender'] == 'Female']\n",
    "\n",
    "# Stack back vertically\n",
    "stacked_df = pd.concat([male_df, female_df], axis=0)\n",
    "print(stacked_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb95ddc",
   "metadata": {},
   "source": [
    "2. Stacking columns (horizontal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3998c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST TO SHOW LOGIC: SAY WE ONLY WANT CUSTOMER AND TOTAL COLUMS#\n",
    "total_df = supmkt_df[['Customer_type', 'Total']]\n",
    "products_df = supmkt_df[['Product_line', 'Unit_price']]\n",
    "\n",
    "#CoMBINE SIDE-BY-SIDE(MUST HAVE THE SAME  UMBER OF ROWS)\n",
    "horiz_concat = pd.concat([total_df, products_df], axis=1)\n",
    "print(horiz_concat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68360d43",
   "metadata": {},
   "source": [
    "üß± pd.concat() ‚Äî Stack Rows (Vertical)\n",
    "‚úÖ Example: Stack sales by Gender\n",
    "Let‚Äôs say you want to split the dataset into male and female customers, and later combine them back. This is vertical stacking.\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec26781",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Split into male and female DataFrames\n",
    "male_df = df[df['Gender'] == 'Male']\n",
    "female_df = df[df['Gender'] == 'Female']\n",
    "\n",
    "# Stack vertically\n",
    "stacked_rows = pd.concat([male_df, female_df], axis=0)\n",
    "\n",
    "# Reset index if needed\n",
    "stacked_rows = stacked_rows.reset_index(drop=True)\n",
    "\n",
    "print(stacked_rows.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd303545",
   "metadata": {},
   "source": [
    "üìå Key Logic:\n",
    "\n",
    "You're adding more rows (like combining pages of a notebook).\n",
    "\n",
    "This is common when merging same-structure data from different time periods, regions, or categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c94ffe",
   "metadata": {},
   "source": [
    "üìå Key Logic:\n",
    "\n",
    "You're adding more rows (like combining pages of a notebook).\n",
    "\n",
    "This is common when merging same-structure data from different time periods, regions, or categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d518917",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_info = df[['Customer_type', 'Gender']]\n",
    "product_info = df[['Product_line', 'Total']]\n",
    "\n",
    "# Stack horizontally (side-by-side)\n",
    "stacked_columns = pd.concat([customer_info, product_info], axis=1)\n",
    "\n",
    "print(stacked_columns.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28f328",
   "metadata": {},
   "source": [
    "üìå Key Logic:\n",
    "\n",
    "You're adding more columns (like adding more fields in a form).\n",
    "\n",
    "Use this when you have different pieces of information (same number of rows) that you want to combine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2ff66",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6ba64db",
   "metadata": {},
   "source": [
    "| Type          | What You Did                               | pd.concat(..., axis=) |\n",
    "| ------------- | ------------------------------------------ | --------------------- |\n",
    "| Stack Rows    | Male + Female sales one after the other    | `axis=0`              |\n",
    "| Stack Columns | Combine selected customer + product fields | `axis=1`              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b11898",
   "metadata": {},
   "source": [
    "üîÅ Why reset_index()?\n",
    "When you split and concatenate like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = pd.concat([male_df, female_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1182d3",
   "metadata": {},
   "source": [
    "The row indices might still be like:\n",
    "0\n",
    "2\n",
    "1\n",
    "3\n",
    "That‚Äôs confusing. So we say:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "stacked = stacked.reset_index(drop=True)\n",
    "To make the row numbers go back to 0, 1, 2, 3 ‚Äî a fresh, clean order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8579e82",
   "metadata": {},
   "source": [
    ".JOIN()\n",
    "\n",
    "Enrich supmkt.csv with Store Info using .join()\n",
    "We‚Äôll combine two CSV-like tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d9f42",
   "metadata": {},
   "source": [
    "üîπ 1. Main Data ‚Äî supmkt.csv (we'll call this main_df):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e196a",
   "metadata": {},
   "source": [
    "| Store\\_ID | Product\\_ID | Product\\_Price |\n",
    "| --------- | ----------- | -------------- |\n",
    "| S001      | P001        | 100            |\n",
    "| S002      | P002        | 150            |\n",
    "| S003      | P003        | 200            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1cce9",
   "metadata": {},
   "source": [
    "üîπ 2. Second Table ‚Äî Store Info (store_info_df):\n",
    "\n",
    "| Store\\_ID | Location      | Manager |\n",
    "| --------- | ------------- | ------- |\n",
    "| S001      | Lagos         | Mr. A   |\n",
    "| S002      | Abuja         | Ms. B   |\n",
    "| S003      | Port Harcourt | Mr. C   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d6ea4",
   "metadata": {},
   "source": [
    "üîß 3. Preparing for the Join\n",
    "We must set Store_ID as index in both tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "supmkt_df.set_index('Store_ID', inplace=True)\n",
    "supmket_df.set_index('Store_ID', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe2e72",
   "metadata": {},
   "source": [
    "üîó 4. Perform the Join\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d68c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df= supmkt_df.join(supmket_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d5c4f",
   "metadata": {},
   "source": [
    "‚úÖ 5. Final Result ‚Äî Joined Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd93e8c3",
   "metadata": {},
   "source": [
    "| Store\\_ID | Product\\_ID | Product\\_Price | Location      | Manager |\n",
    "| --------- | ----------- | -------------- | ------------- | ------- |\n",
    "| S001      | P001        | 100            | Lagos         | Mr. A   |\n",
    "| S002      | P002        | 150            | Abuja         | Ms. B   |\n",
    "| S003      | P003        | 200            | Port Harcourt | Mr. C   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794778a",
   "metadata": {},
   "source": [
    "üß† What You Learned\n",
    ".join() combines DataFrames using the index.\n",
    "\n",
    "Acts like a SQL LEFT JOIN by default.\n",
    "\n",
    "Clean and simple when both tables share a common index (like Store_ID).\n",
    "\n",
    "Best for adding extra columns (info) without reshuffling rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4246443",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
